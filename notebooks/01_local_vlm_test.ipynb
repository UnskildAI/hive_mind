{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local VLM Testing: Moondream2\n",
    "\n",
    "This notebook tests the [Moondream2](https://huggingface.co/vikhyatk/moondream2) model locally on your laptop. Moondream2 is a small (1.6B) vision-language model optimized for speed and efficiency, making it ideal for local CPU/iGPU execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "Install necessary packages if you haven't already:\n",
    "```bash\n",
    "pip install transformers timm pillow einops\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca2a7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mecha/hive_mind/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mecha/hive_mind/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/mecha/hive_mind/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Moondream2 loaded\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "transformers_modules.vikhyatk.moondream2.4a8fa31450e8def597abae38a8fa915d18e90b9f.moondream.Moondream.generate() got multiple values for keyword argument 'max_new_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     53\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mDescribe what is in this image.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     answer = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43manswer_question\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimage_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Output\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mQuestion:\u001b[39m\u001b[33m\"\u001b[39m, question)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/4a8fa31450e8def597abae38a8fa915d18e90b9f/moondream.py:92\u001b[39m, in \u001b[36mMoondream.answer_question\u001b[39m\u001b[34m(self, image_embeds, question, tokenizer, chat_history, result_queue, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34manswer_question\u001b[39m(\n\u001b[32m     83\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     84\u001b[39m     image_embeds,\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     **kwargs,\n\u001b[32m     90\u001b[39m ):\n\u001b[32m     91\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<image>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mchat_history\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAnswer: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     answer = \u001b[38;5;28mself\u001b[39m.generate(\n\u001b[32m     93\u001b[39m         image_embeds,\n\u001b[32m     94\u001b[39m         prompt,\n\u001b[32m     95\u001b[39m         eos_text=\u001b[33m\"\u001b[39m\u001b[33m<END>\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     96\u001b[39m         tokenizer=tokenizer,\n\u001b[32m     97\u001b[39m         max_new_tokens=\u001b[32m256\u001b[39m,\n\u001b[32m     98\u001b[39m         **kwargs,\n\u001b[32m     99\u001b[39m     )[\u001b[32m0\u001b[39m]\n\u001b[32m    100\u001b[39m     cleaned_answer = re.sub(\u001b[33m\"\u001b[39m\u001b[33m<$|<END$\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, answer).strip()\n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# Use the result_queue to pass the result if it is provided\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: transformers_modules.vikhyatk.moondream2.4a8fa31450e8def597abae38a8fa915d18e90b9f.moondream.Moondream.generate() got multiple values for keyword argument 'max_new_tokens'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# -----------------------\n",
    "# Device\n",
    "# -----------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "# -----------------------\n",
    "# Load Moondream2 (PINNED)\n",
    "# -----------------------\n",
    "model_id = \"vikhyatk/moondream2\"\n",
    "revision = \"2024-03-05\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    revision=revision,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=None,  # IMPORTANT: Moondream handles devices internally\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    revision=revision\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"✅ Moondream2 loaded\")\n",
    "\n",
    "# -----------------------\n",
    "# Download + load image\n",
    "# -----------------------\n",
    "url = \"https://t3.ftcdn.net/jpg/05/65/52/64/360_F_565526485_9U4G08e8P2N8U9QW6X7X6I0zX6V1P4q6.jpg\"\n",
    "image = Image.open(BytesIO(requests.get(url).content)).convert(\"RGB\")\n",
    "\n",
    "# -----------------------\n",
    "# Encode image\n",
    "# -----------------------\n",
    "with torch.no_grad():\n",
    "    image_embeds = model.encode_image(image)\n",
    "\n",
    "# -----------------------\n",
    "# Ask question\n",
    "# -----------------------\n",
    "question = \"Describe what is in this image.\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    answer = model.answer_question(\n",
    "        image_embeds,\n",
    "        question,\n",
    "        tokenizer\n",
    "    )\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Output\n",
    "# -----------------------\n",
    "print(\"\\nQuestion:\", question)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Check for available device\n",
    "device = \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encountered exception while importing timm: No module named 'timm'\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "This modeling file requires the following packages that were not found in your environment: timm. Run `pip install timm`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m model_id = \u001b[33m\"\u001b[39m\u001b[33mvikhyatk/moondream2\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m revision = \u001b[33m\"\u001b[39m\u001b[33m2024-03-05\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# Using a stable revision\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n\u001b[32m      9\u001b[39m model.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hive_mind/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:586\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    583\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33madapter_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = adapter_kwargs\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m     model_class = \u001b[43mget_class_from_dynamic_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    589\u001b[39m     _ = hub_kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    590\u001b[39m     \u001b[38;5;66;03m# This block handles the case where the user is loading a model with `trust_remote_code=True`\u001b[39;00m\n\u001b[32m    591\u001b[39m     \u001b[38;5;66;03m# but a library model exists with the same name. We don't want to override the autoclass\u001b[39;00m\n\u001b[32m    592\u001b[39m     \u001b[38;5;66;03m# mappings in this case, or all future loads of that model will be the remote code model.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hive_mind/.venv/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:604\u001b[39m, in \u001b[36mget_class_from_dynamic_module\u001b[39m\u001b[34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     code_revision = revision\n\u001b[32m    603\u001b[39m \u001b[38;5;66;03m# And lastly we get the class inside our newly created module\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m final_module = \u001b[43mget_cached_module_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule_file\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.py\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m get_class_in_module(class_name, final_module, force_reload=force_download)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hive_mind/.venv/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:467\u001b[39m, in \u001b[36mget_cached_module_file\u001b[39m\u001b[34m(pretrained_model_name_or_path, module_file, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module_needed \u001b[38;5;129;01min\u001b[39;00m modules_needed:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ((submodule_path / module_file).parent / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_needed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m).exists():\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m             \u001b[43mget_cached_module_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m/\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mmodule_needed\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.py\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m                \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m                \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m                \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m                \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m             new_files.append(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_needed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_files) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hive_mind/.venv/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:427\u001b[39m, in \u001b[36mget_cached_module_file\u001b[39m\u001b[34m(pretrained_model_name_or_path, module_file, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[38;5;66;03m# Check we have all the requirements in our environment\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m modules_needed = \u001b[43mcheck_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_module_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Now we move the module inside our cached dynamic modules.\u001b[39;00m\n\u001b[32m    430\u001b[39m full_submodule = TRANSFORMERS_DYNAMIC_MODULE_NAME + os.path.sep + submodule\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hive_mind/.venv/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:260\u001b[39m, in \u001b[36mcheck_imports\u001b[39m\u001b[34m(filename)\u001b[39m\n\u001b[32m    257\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_packages) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    261\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis modeling file requires the following packages that were not found in your environment: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    262\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(missing_packages)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Run `pip install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(missing_packages)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    263\u001b[39m     )\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m get_relative_imports(filename)\n",
      "\u001b[31mImportError\u001b[39m: This modeling file requires the following packages that were not found in your environment: timm. Run `pip install timm`"
     ]
    }
   ],
   "source": [
    "model_id = \"vikhyatk/moondream2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    trust_remote_code=True, \n",
    "    revision=revision\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model.to(device)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visual Reasoning Test\n",
    "\n",
    "Let's test the model with a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a sample image (or use a local path)\n",
    "url = \"https://t3.ftcdn.net/jpg/05/65/52/64/360_F_565526485_9U4G08e8P2N8U9QW6X7X6I0zX6V1P4q6.jpg\" # Sample robot image\n",
    "response = requests.get(url)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "display(image.resize((300, 300)))\n",
    "\n",
    "enc_image = model.encode_image(image)\n",
    "question = \"Describe what is in this image.\"\n",
    "answer = model.answer_question(enc_image, question, tokenizer)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is there a robot in the image? If so, what is it doing?\"\n",
    "answer = model.answer_question(enc_image, question, tokenizer)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hive-mind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
